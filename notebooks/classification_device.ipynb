{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lTI_Sx0_90e"
   },
   "source": [
    "# Train Neural Network\n",
    "## Parse and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVOiR1uQKzpy",
    "outputId": "e2797aae-fc03-4def-a699-308a495dce0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version = 2.6.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import fileinput\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Ftrl\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "import time\n",
    "\n",
    "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
    "\n",
    "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
    "# the same random numbers each time the notebook is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['box-own', 'laptop-own', 'monitor-combined', 'pc-combined', 'phone-own', 'printer-combined', 'switch-afstand', 'tv_combined']\n"
     ]
    }
   ],
   "source": [
    "# SEED = 1337\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "\n",
    "CLASSES = [];\n",
    "\n",
    "# get all csv files and uses their names for the classes\n",
    "for file in os.listdir(\"../data/17-04\"):\n",
    "    if file.endswith(\".csv\"):\n",
    "        CLASSES.append(os.path.splitext(file)[0])\n",
    "# sort the classes\n",
    "CLASSES.sort()\n",
    "\n",
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "YxYCUqzTAJeX",
    "outputId": "f5942731-9f3c-4ebf-ae67-d3c44d958173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;4mbox-own\u001b[0m class will be output \u001b[32m0\u001b[0m of the classifier\n",
      "2629 samples captured for training with inputs ['ApparentPower', 'Current', 'Power', 'ReactivePower'] \n",
      "\n",
      "\u001b[32;4mlaptop-own\u001b[0m class will be output \u001b[32m1\u001b[0m of the classifier\n",
      "1037 samples captured for training with inputs ['ApparentPower', 'Current', 'Power', 'ReactivePower'] \n",
      "\n",
      "\u001b[32;4mmonitor-combined\u001b[0m class will be output \u001b[32m2\u001b[0m of the classifier\n",
      "7143 samples captured for training with inputs ['ApparentPower', 'Current', 'Power', 'ReactivePower'] \n",
      "\n",
      "\u001b[32;4mpc-combined\u001b[0m class will be output \u001b[32m3\u001b[0m of the classifier\n",
      "17245 samples captured for training with inputs ['ApparentPower', 'Current', 'Power', 'ReactivePower'] \n",
      "\n",
      "\u001b[32;4mphone-own\u001b[0m class will be output \u001b[32m4\u001b[0m of the classifier\n",
      "226 samples captured for training with inputs ['ApparentPower', 'Current', 'Power', 'ReactivePower'] \n",
      "\n",
      "\u001b[32;4mprinter-combined\u001b[0m class will be output \u001b[32m5\u001b[0m of the classifier\n",
      "9933 samples captured for training with inputs ['ApparentPower', 'Current', 'Power', 'ReactivePower'] \n",
      "\n",
      "\u001b[32;4mswitch-afstand\u001b[0m class will be output \u001b[32m6\u001b[0m of the classifier\n",
      "286 samples captured for training with inputs ['ApparentPower', 'Current', 'Power', 'ReactivePower'] \n",
      "\n",
      "\u001b[32;4mtv_combined\u001b[0m class will be output \u001b[32m7\u001b[0m of the classifier\n",
      "6180 samples captured for training with inputs ['ApparentPower', 'Current', 'Power', 'ReactivePower'] \n",
      "\n",
      "(120,)\n",
      "['box-own', 'laptop-own', 'monitor-combined', 'pc-combined', 'phone-own', 'printer-combined', 'switch-afstand', 'tv_combined']\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(CLASSES) # get the number of classes\n",
    "\n",
    "# create a one-hot encoded matrix that is used in the output\n",
    "ONE_HOT_ENCODED_CLASSES = np.eye(NUM_CLASSES)\n",
    "\n",
    "# the input and output tensor\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "# determines how many samples to use for each input\n",
    "SAMPLES_PER_CLASS = 30\n",
    "\n",
    "# read each csv file and push an input and output\n",
    "for class_index in range(NUM_CLASSES):\n",
    "  objectClass = CLASSES[class_index]\n",
    "  df = pd.read_csv(\"../data/17-04/\" + objectClass + \".csv\")\n",
    "  # drop any unused parameters\n",
    "  df = df.drop(columns=['time'])\n",
    "  df = df.drop(columns=['Voltage'])\n",
    "  df = df.drop(columns=['Factor'])\n",
    "  columns = list(df)\n",
    "  # get rid of empty value lines of csv which cause NaN inputs to TensorFlow\n",
    "  df = df.dropna()\n",
    "  df = df.reset_index(drop=True)\n",
    "\n",
    "  # calculate the number of objectClass recordings in the file\n",
    "  num_recordings = int(df.shape[0] / SAMPLES_PER_CLASS)\n",
    "  print(f\"\\u001b[32;4m{objectClass}\\u001b[0m class will be output \\u001b[32m{class_index}\\u001b[0m of the classifier\")\n",
    "  print(f\"{num_recordings} samples captured for training with inputs {list(df)} \\n\")\n",
    "  \n",
    "  #tensors\n",
    "  output = ONE_HOT_ENCODED_CLASSES[class_index]\n",
    "  # fill the input and output tensors\n",
    "  for i in range(num_recordings):\n",
    "    tensor = []\n",
    "    for j in range(SAMPLES_PER_CLASS):\n",
    "        # the index of the next sample to add\n",
    "        index = i * SAMPLES_PER_CLASS + j\n",
    "        tensor += [\n",
    "            df['ApparentPower'][index],\n",
    "            df['Current'][index],\n",
    "            # df['Factor'][index],\n",
    "            df['Power'][index],\n",
    "            df['ReactivePower'][index],        \n",
    "        ]\n",
    "    inputs.append(tensor)\n",
    "    outputs.append(output)\n",
    "\n",
    "# convert the list to numpy array\n",
    "inputs = np.array(inputs)\n",
    "\n",
    "# Scale the columns of X to be between 0 and 1 using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "inputs_scaled = scaler.fit_transform(inputs)\n",
    "joblib.dump(scaler, 'scaler.gz')\n",
    "\n",
    "# print shape of an input\n",
    "print(inputs[0].shape)\n",
    "outputs = np.array(outputs) # convert the outputs to a numpy array\n",
    "print(CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OGt81LcfVetr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set randomization and splitting complete.\n",
      "[[0.02554028 0.0294365  0.01126126 ... 0.02850755 0.01121076 0.03661972]\n",
      " [0.01571709 0.01654051 0.0045045  ... 0.01453326 0.0044843  0.01971831]\n",
      " [0.01178782 0.01261564 0.00225225 ... 0.00894354 0.         0.01408451]\n",
      " ...\n",
      " [0.18860511 0.22960471 0.20045045 ... 0.23420906 0.19955157 0.11267606]\n",
      " [0.00589391 0.006448   0.00225225 ... 0.00503074 0.00224215 0.0084507 ]\n",
      " [0.00392927 0.00364452 0.00225225 ... 0.00670766 0.00224215 0.01126761]]\n",
      "44679\n"
     ]
    }
   ],
   "source": [
    "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
    "# https://stackoverflow.com/a/37710486/2020087\n",
    "num_inputs = len(inputs)\n",
    "randomize = np.arange(num_inputs)\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
    "inputs_scaled = inputs_scaled[randomize]\n",
    "outputs = outputs[randomize]\n",
    "\n",
    "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
    "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
    "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
    "\n",
    "inputs_train, inputs_test, inputs_validate = np.split(inputs_scaled, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "print(\"Data set randomization and splitting complete.\")\n",
    "print(inputs_test)\n",
    "print(num_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Enr4twhJJgex"
   },
   "source": [
    "# Test code voor de tijd in de csv om te zetten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_snKH6OAPx4"
   },
   "source": [
    "#Build & Train the Model\n",
    "Build and train a TensorFlow model using the high-level Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "Ic2Z4XtgAaNh",
    "outputId": "ed119d8f-6237-4813-9575-9ae579eea919"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 13:52:03.659199: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-05-04 13:52:03.659217: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 9712c8604b07\n",
      "2023-05-04 13:52:03.659221: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 9712c8604b07\n",
      "2023-05-04 13:52:03.659262: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.105.17\n",
      "2023-05-04 13:52:03.659272: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.105.17\n",
      "2023-05-04 13:52:03.659275: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.105.17\n",
      "2023-05-04 13:52:03.659469: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 13:52:03.743938: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  10  | loss:  0.012057509273290634 | val_loss:  0.010248799808323383 | accuracy:  0.9500951102159562\n",
      "epoch:  20  | loss:  0.010103769600391388 | val_loss:  0.008686400949954987 | accuracy:  0.9572563500055947\n",
      "epoch:  30  | loss:  0.005903718527406454 | val_loss:  0.004120195750147104 | accuracy:  0.9782924918876581\n",
      "epoch:  40  | loss:  0.005252835340797901 | val_loss:  0.004258202388882637 | accuracy:  0.9806422736936332\n",
      "epoch:  50  | loss:  0.004474283661693335 | val_loss:  0.003557030111551285 | accuracy:  0.9824325836410428\n",
      "epoch:  60  | loss:  0.004522552713751793 | val_loss:  0.003913470543920994 | accuracy:  0.9817612174107643\n",
      "epoch:  70  | loss:  0.003772989846765995 | val_loss:  0.0033340773079544306 | accuracy:  0.9846704710753049\n",
      "epoch:  80  | loss:  0.003979701083153486 | val_loss:  0.00329806050285697 | accuracy:  0.9837753161016001\n",
      "epoch:  90  | loss:  0.003955136518925428 | val_loss:  0.003283480415120721 | accuracy:  0.9850061541904442\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/getting-started/174307\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# callback to only print metrics every X epochs\n",
    "class Callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X = X_val\n",
    "        self.y = y_val.argmax(axis=1)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch == 0:\n",
    "            return\n",
    "        if epoch%10==0: #Hier aanpassan na hoeveel epochs je wilt zien\n",
    "            pred = (model.predict(self.X))\n",
    "            print('epoch: ',epoch, ' | loss: ', str(logs['loss']), '| val_loss: ', str(logs['val_loss']), '| accuracy: ', accuracy_score(self.y,pred.argmax(axis=1)))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10) # early stopping -> will sotp training if no improvement for 10 epochs\n",
    "# build the model and train it\n",
    "model = tf.keras.Sequential()\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu')) # relu is used for performance (50\n",
    "model.add(Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu')) #30\n",
    "model.add(Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu')) #20\n",
    "model.add(Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')) # softmax is used, because we only expect one class to occur per input\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(inputs_train, outputs_train, epochs=150, batch_size=16, validation_data=(inputs_validate, outputs_validate), callbacks=[Callback(inputs_validate, outputs_validate)], verbose=0)\n",
    "model.summary() #500 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "gmiRMLprEbZf",
    "outputId": "73f32a27-735e-4ad0-91ff-959ad8e0de97"
   },
   "outputs": [],
   "source": [
    "# get the training loss and validation loss history values\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# the number of epochs\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "# plot the training and validation loss\n",
    "plt.plot(epochs, loss, 'g.', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b.', label=\"val loss\")\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNp0t-ELAf5t"
   },
   "source": [
    "# Run with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "kRxeKbcPAl1W",
    "outputId": "3d93a119-87d0-495e-9914-5caff7f8cc9d"
   },
   "outputs": [],
   "source": [
    "# use the model to predict the test inputs\n",
    "predictions = model.predict(inputs_test)\n",
    "print(inputs_test.shape)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# print the predictions and the expected ouputs\n",
    "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
    "print(\"actual =\\n\", outputs_test)\n",
    "\n",
    "y_prediction = np.argmax(predictions, axis = 1)\n",
    "y_test=np.argmax(outputs_test, axis=1)\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_test, y_prediction , normalize='pred')\n",
    "disp =  ConfusionMatrixDisplay(confusion_matrix=result)\n",
    "print(result)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save('classification_17-04V3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the notebook\n",
    "!tar chvfz notebook.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
