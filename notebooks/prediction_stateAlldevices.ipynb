{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9631555d-5496-4917-97e6-e094d49d618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41165/2589086162.py:19: UserWarning: No GPU found.\n",
      "  warnings.warn(\"No GPU found.\")\n",
      "2023-05-22 13:24:47.658049: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 13:24:47.679000: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-05-22 13:24:47.679015: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 9712c8604b07\n",
      "2023-05-22 13:24:47.679018: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 9712c8604b07\n",
      "2023-05-22 13:24:47.679064: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.105.17\n",
      "2023-05-22 13:24:47.679075: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.105.17\n",
      "2023-05-22 13:24:47.679078: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 525.105.17\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn(\"No GPU found.\")\n",
    "else: \n",
    "    print('Default gpu device: {}' .format(tf.test.gpu_device_name()))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e8159c-a208-40cf-89e8-d3390b528ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                timestamp  state  hour  minute  day_of_week  device\n",
      "0     2023-01-02 00:00:00      1     0       0            0       1\n",
      "1     2023-01-02 00:04:00      1     0       4            0       1\n",
      "2     2023-01-02 00:08:00      1     0       8            0       1\n",
      "3     2023-01-02 00:12:00      1     0      12            0       1\n",
      "4     2023-01-02 00:16:00      1     0      16            0       1\n",
      "...                   ...    ...   ...     ...          ...     ...\n",
      "10075 2023-01-29 23:40:00      0    23      40            6       1\n",
      "10076 2023-01-29 23:44:00      0    23      44            6       1\n",
      "10077 2023-01-29 23:48:00      0    23      48            6       1\n",
      "10078 2023-01-29 23:52:00      0    23      52            6       1\n",
      "10079 2023-01-29 23:56:00      0    23      56            6       1\n",
      "\n",
      "[10080 rows x 6 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>state</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02 00:04:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-02 00:08:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-02 00:12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-02 00:16:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  state  hour  minute  day_of_week  device\n",
       "0 2023-01-02 00:00:00    0.0     0       0            0       0\n",
       "1 2023-01-02 00:04:00    0.0     0       4            0       0\n",
       "2 2023-01-02 00:08:00    0.0     0       8            0       0\n",
       "3 2023-01-02 00:12:00    0.0     0      12            0       0\n",
       "4 2023-01-02 00:16:00    0.0     0      16            0       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(filename, resample=False, integer_timestamp=False):\n",
    "    # Load in the data\n",
    "    df = pd.read_csv(filename, parse_dates=['timestamp'])\n",
    "    \n",
    "    # drop nan values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # set timestamp as index and drop timestamp column\n",
    "    df.index = pd.to_datetime(df['timestamp'], format='%Y.%m.%d %H:%M:%S')\n",
    "    df = df.drop(columns=['timestamp'])\n",
    "\n",
    "    if(resample):\n",
    "        # Resample the DataFrame to 4 minutes frequency if needed\n",
    "        df = df.resample('4T').mean()\n",
    "    if(integer_timestamp):\n",
    "        # use if the timestamp is a integer\n",
    "        to_datetime = lambda x: datetime.datetime.fromtimestamp(x/1000.0)\n",
    "        df['timestamp'] = df['timestamp'].astype(float)\n",
    "        df['timestamp'] = df['timestamp'].apply(to_datetime)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "df_laptop = load_data(r'../data/multiple_devices/new_weeks/pc_jarno_4w_allsame.csv')\n",
    "df_box = load_data(r'../data/multiple_devices/new_weeks/synthetic_test_4w_allsame.csv')\n",
    "df_pc = load_data(r'../data/multiple_devices/new_weeks/PCSynth.csv')\n",
    "df_printer = load_data(r'../data/multiple_devices/new_weeks/PrinterSynth.csv')\n",
    "df_phone = load_data(r'../data/multiple_devices/new_weeks/PhoneSynth.csv')\n",
    "\n",
    "\n",
    "def add_time_features(df):\n",
    "    # add hour, minute, day of the week and month parameters\n",
    "    df['hour'] = df.index.hour\n",
    "    df['minute'] = df.index.minute\n",
    "    # df['day_of_month'] = df.index.day\n",
    "    df['day_of_week'] = df.index.dayofweek\n",
    "    # df['month'] = df.index.month\n",
    "    return df\n",
    "\n",
    "# add time features to the datasets\n",
    "df_laptop = add_time_features(df_laptop)\n",
    "df_box = add_time_features(df_box)\n",
    "df_pc = add_time_features(df_pc)\n",
    "df_printer = add_time_features(df_printer)\n",
    "df_phone = add_time_features(df_phone)\n",
    "\n",
    "# reset the index so it is not a timestamp index but just a number\n",
    "df_laptop = df_laptop.reset_index()\n",
    "df_box = df_box.reset_index()\n",
    "df_pc = df_pc.reset_index()\n",
    "df_printer = df_printer.reset_index()\n",
    "df_phone = df_phone.reset_index()\n",
    "\n",
    "# create a list of the dataframes\n",
    "dfs = [df_box,df_laptop,df_pc,df_phone,df_printer]\n",
    "\n",
    "# loop through the list of dataframes and assign a value to a new column called 'device'\n",
    "for i, df in enumerate(dfs):\n",
    "    df['device'] = i\n",
    "\n",
    "\n",
    "combined_df = pd.concat([df_box,df_laptop,df_pc,df_phone,df_printer])\n",
    "combined_df = combined_df.drop(columns=['timestamp'])\n",
    "\n",
    "\n",
    "# print(combined_df)\n",
    "# print(\"done\")\n",
    "print(df_laptop)\n",
    "df_box.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ea57d2-c874-4a58-b693-a56dfab49e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add column for state\n",
    "# df['state'] = np.where(df['power'] > 5, 1, 0)\n",
    "# # df['state'] = np.where(df['power'] > 50, 1, 0)\n",
    "# df = df.drop(columns=['power']) # not sure if power is a valuable parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17efa4b4-abc5-4df3-83b6-c95410bed621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  hour  minute  day_of_week  device\n",
       "0    0.0     0       0            0       0\n",
       "1    0.0     0       4            0       0\n",
       "2    0.0     0       8            0       0\n",
       "3    0.0     0      12            0       0\n",
       "4    0.0     0      16            0       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b2fcd6-78a9-471e-92d1-db142b38ba8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50400.000000</td>\n",
       "      <td>50400.000000</td>\n",
       "      <td>50400.000000</td>\n",
       "      <td>50400.00000</td>\n",
       "      <td>50400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.345952</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.475682</td>\n",
       "      <td>6.922255</td>\n",
       "      <td>17.282147</td>\n",
       "      <td>2.00002</td>\n",
       "      <td>1.414228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              state          hour        minute  day_of_week        device\n",
       "count  50400.000000  50400.000000  50400.000000  50400.00000  50400.000000\n",
       "mean       0.345952     11.500000     28.000000      3.00000      2.000000\n",
       "std        0.475682      6.922255     17.282147      2.00002      1.414228\n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000\n",
       "25%        0.000000      5.750000     12.000000      1.00000      1.000000\n",
       "50%        0.000000     11.500000     28.000000      3.00000      2.000000\n",
       "75%        1.000000     17.250000     44.000000      5.00000      3.000000\n",
       "max        1.000000     23.000000     56.000000      6.00000      4.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88993a0-52e9-432d-91b5-844204c9b3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       state  hour    minute  day_of_week  device\n",
      "0        0.0  -1.0 -1.000000         -1.0    -1.0\n",
      "1        0.0  -1.0 -0.857143         -1.0    -1.0\n",
      "2        0.0  -1.0 -0.714286         -1.0    -1.0\n",
      "3        0.0  -1.0 -0.571429         -1.0    -1.0\n",
      "4        0.0  -1.0 -0.428571         -1.0    -1.0\n",
      "...      ...   ...       ...          ...     ...\n",
      "10075    1.0   1.0  0.428571          1.0    -1.0\n",
      "10076    1.0   1.0  0.571429          1.0    -1.0\n",
      "10077    0.0   1.0  0.714286          1.0    -1.0\n",
      "10078    0.0   1.0  0.857143          1.0    -1.0\n",
      "10079    0.0   1.0  1.000000          1.0    -1.0\n",
      "\n",
      "[10080 rows x 5 columns]\n",
      "       state  hour    minute  day_of_week  device\n",
      "0          1  -1.0 -1.000000         -1.0    -0.5\n",
      "1          1  -1.0 -0.857143         -1.0    -0.5\n",
      "2          1  -1.0 -0.714286         -1.0    -0.5\n",
      "3          1  -1.0 -0.571429         -1.0    -0.5\n",
      "4          1  -1.0 -0.428571         -1.0    -0.5\n",
      "...      ...   ...       ...          ...     ...\n",
      "10075      0   1.0  0.428571          1.0    -0.5\n",
      "10076      0   1.0  0.571429          1.0    -0.5\n",
      "10077      0   1.0  0.714286          1.0    -0.5\n",
      "10078      0   1.0  0.857143          1.0    -0.5\n",
      "10079      0   1.0  1.000000          1.0    -0.5\n",
      "\n",
      "[10080 rows x 5 columns]\n",
      "       state  hour    minute  day_of_week  device\n",
      "0          1  -1.0 -1.000000         -1.0     0.0\n",
      "1          1  -1.0 -0.857143         -1.0     0.0\n",
      "2          1  -1.0 -0.714286         -1.0     0.0\n",
      "3          1  -1.0 -0.571429         -1.0     0.0\n",
      "4          1  -1.0 -0.428571         -1.0     0.0\n",
      "...      ...   ...       ...          ...     ...\n",
      "10075      1   1.0  0.428571          1.0     0.0\n",
      "10076      1   1.0  0.571429          1.0     0.0\n",
      "10077      1   1.0  0.714286          1.0     0.0\n",
      "10078      1   1.0  0.857143          1.0     0.0\n",
      "10079      1   1.0  1.000000          1.0     0.0\n",
      "\n",
      "[10080 rows x 5 columns]\n",
      "       state  hour    minute  day_of_week  device\n",
      "0          1  -1.0 -1.000000         -1.0     1.0\n",
      "1          1  -1.0 -0.857143         -1.0     1.0\n",
      "2          1  -1.0 -0.714286         -1.0     1.0\n",
      "3          1  -1.0 -0.571429         -1.0     1.0\n",
      "4          1  -1.0 -0.428571         -1.0     1.0\n",
      "...      ...   ...       ...          ...     ...\n",
      "10075      0   1.0  0.428571          1.0     1.0\n",
      "10076      0   1.0  0.571429          1.0     1.0\n",
      "10077      0   1.0  0.714286          1.0     1.0\n",
      "10078      0   1.0  0.857143          1.0     1.0\n",
      "10079      0   1.0  1.000000          1.0     1.0\n",
      "\n",
      "[10080 rows x 5 columns]\n",
      "       state  hour    minute  day_of_week  device\n",
      "0          0  -1.0 -1.000000         -1.0     0.5\n",
      "1          0  -1.0 -0.857143         -1.0     0.5\n",
      "2          0  -1.0 -0.714286         -1.0     0.5\n",
      "3          0  -1.0 -0.571429         -1.0     0.5\n",
      "4          0  -1.0 -0.428571         -1.0     0.5\n",
      "...      ...   ...       ...          ...     ...\n",
      "10075      0   1.0  0.428571          1.0     0.5\n",
      "10076      0   1.0  0.571429          1.0     0.5\n",
      "10077      0   1.0  0.714286          1.0     0.5\n",
      "10078      0   1.0  0.857143          1.0     0.5\n",
      "10079      0   1.0  1.000000          1.0     0.5\n",
      "\n",
      "[10080 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "# drop timestamp column\n",
    "df_laptop = df_laptop.drop(columns=['timestamp'])\n",
    "df_box = df_box.drop(columns=['timestamp'])\n",
    "df_pc = df_pc.drop(columns=['timestamp'])\n",
    "df_printer = df_printer.drop(columns=['timestamp'])\n",
    "df_phone = df_phone.drop(columns=['timestamp'])\n",
    "\n",
    "# normalize our features, scale on all values first (combined)\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "combined_df[['hour','minute','day_of_week', 'device']] = scaler.fit_transform(combined_df[['hour','minute','day_of_week','device']])\n",
    "\n",
    "# scale the seperate data\n",
    "df_box[['hour','minute','day_of_week', 'device']] = scaler.transform(df_box[['hour','minute','day_of_week', 'device']])\n",
    "df_laptop[['hour','minute','day_of_week', 'device']] = scaler.transform(df_laptop[['hour','minute','day_of_week', 'device']])\n",
    "df_pc[['hour','minute','day_of_week', 'device']] = scaler.transform(df_pc[['hour','minute','day_of_week', 'device']])\n",
    "df_printer[['hour','minute','day_of_week', 'device']] = scaler.transform(df_printer[['hour','minute','day_of_week', 'device']])\n",
    "df_phone[['hour','minute','day_of_week', 'device']] = scaler.transform(df_phone[['hour','minute','day_of_week', 'device']])\n",
    "\n",
    "joblib.dump(scaler, './scaler_boxpc.gz') # save the scaler\n",
    "\n",
    "print(df_box)\n",
    "print(df_laptop)\n",
    "print(df_pc)\n",
    "print(df_printer)\n",
    "print(df_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "896e4fee-c706-4c2d-a3cb-b6aa86e4779a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6048 4032\n",
      "6048 4032\n",
      "6048 4032\n",
      "6048 4032\n",
      "6048 4032\n"
     ]
    }
   ],
   "source": [
    "def split_train_test(df):\n",
    "    train_size = int(len(df) * 0.6)\n",
    "    test_size = len(df) - train_size\n",
    "    train, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]\n",
    "    return train, test\n",
    "\n",
    "# split the datasets into training and testing sets\n",
    "train, test = split_train_test(df_laptop)\n",
    "# train_sille, test_sille = split_train_test(df_generated2)\n",
    "train_box, test_box = split_train_test(df_box)\n",
    "train_pc, test_pc = split_train_test(df_pc)\n",
    "train_printer, test_printer = split_train_test(df_printer)\n",
    "train_phone, test_phone = split_train_test(df_phone)\n",
    "\n",
    "# print the size of the training and testing sets for each dataset\n",
    "print(len(train), len(test))\n",
    "# print(len(train_sille), len(test_sille))\n",
    "print(len(train_box), len(test_box))\n",
    "print(len(train_pc), len(test_pc))\n",
    "print(len(train_printer), len(test_printer))\n",
    "print(len(train_phone), len(test_phone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f881e2-424b-4d8a-92d8-5862109f7afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6048, 5), (4032, 5))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2bd7913-bd48-458b-9291-12e6893ef14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(input, output, time_steps=1):\n",
    "    x,y = [], []\n",
    "    for i in range(len(input) - time_steps):\n",
    "        v = input.iloc[i:(i + time_steps)].values\n",
    "        x.append(v)\n",
    "        y.append(output.iloc[i + time_steps])\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4d5503a-49e0-4289-acaa-a45b75e9bcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17640, 2520, 5) (7560, 2520, 5) (17640,) (7560,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUrElEQVR4nO3dfYxcV33G8e+zu96ddey9JvHaM36rQ+UAFk0gXUJaREtLKU6CcJGqkkCBpiDLUkJp1aoJQqV/ICEq2kIpIZaVpgGBiBCkxaWGgCiFPyAoDoUkjpuwCiVe1o43L36LX9br/fWPmXWG9b6M7Rnfvec+H8nKzp3r2UfW+snxmXPmKCIwM7Pi68o7gJmZtYcL3cwsES50M7NEuNDNzBLhQjczS0RPXt94+fLlsX79+ry+vZlZIT300EPPRMTgTM/lVujr169n165deX17M7NCkvTz2Z7zlIuZWSJc6GZmiXChm5klwoVuZpYIF7qZWSLmLXRJd0s6IOnRWZ6XpE9JGpb0sKSr2x/TzMzm08oI/R5g0xzPXwdsaPzaAtx54bHMzOxczbsOPSK+J2n9HLdsBj4X9c/hfUDSMkm1iNjXrpDNHt9/hP98eLQTL20F9JarVnHFyqV5xzBbENqxsWg1sLfp8Ujj2lmFLmkL9VE869atO69vNnzgKP/8neHz+r2WlgjY+/xxPvH2V+UdxWxBaEeha4ZrM56aERHbge0AQ0ND53Wyxg1X1rjhyhvO57daYv5o2w8YPXg87xhmC0Y7VrmMAGubHq8BPCdiHVfNKuw/fCLvGGYLRjsKfQfw7sZql2uBQ52aPzdrVssq7Dt0Ah+jaFY375SLpC8CbwCWSxoB/hZYBBAR24CdwPXAMHAMuLlTYc2aVbMK4xOTPPfCOJct6cs7jlnuWlnlctM8zwdwS9sSmbWollUA2HfohAvdDO8UtQKrZf0A7D/keXQzcKFbgZ0ZofuNUTPAhW4FdtmSPnq6xP5DXrpoBi50K7DuLrFyoMK+gx6hm4EL3Qqu2li6aGYudCs4by4ye5EL3QqtNlBh36Hj3lxkhgvdCq62rJ8TpyY5dPxU3lHMcudCt0Jr3lxkVnYudCu0aqPQvbnIzIVuBTc1Qh/1WnQzF7oV2+CSPrrkEboZuNCt4Hq6u1ix1GvRzcCFbgmoLat4hG6GC90SUD/ownPoZi50K7zqQL9PLjLDhW4JqGUVjo2f5vCJibyjmOXKhW6F57XoZnUudCu8F3eLeh7dys2FboXnEbpZnQvdCm/lQAXJn+di5kK3wlvU3cXgkj6P0K30XOiWhFpW8ee5WOm50C0J1cy7Rc1c6JaEWtbvQrfSc6FbEqpZhSMnJzhywicXWXm50C0JU2vRn/aB0VZiLnRLQi3rB7x00crNhW5J8NmiZi50S8SKgT4A9h10oVt5udAtCX093Sxf0sv+w16LbuXVUqFL2iTpcUnDkm6f4flM0n9I+omk3ZJubn9Us7lVMx9FZ+U2b6FL6gbuAK4DNgI3Sdo47bZbgMci4irgDcA/SOptc1azOXktupVdKyP0a4DhiHgyIsaBe4HN0+4JYKkkAUuA5wCfNmAXVc0jdCu5Vgp9NbC36fFI41qzTwOvAEaBR4APRMTk9BeStEXSLkm7xsbGzjOy2cyqWYVDx09xbNxjCSunVgpdM1ybfnjjm4EfA6uAVwGfljRw1m+K2B4RQxExNDg4eI5RzebmpYtWdq0U+giwtunxGuoj8WY3A/dF3TDwM+Dl7Ylo1prqQH1zkefRraxaKfQHgQ2SLm+80XkjsGPaPU8BbwSQtBJ4GfBkO4OazccjdCu7nvluiIgJSbcC9wPdwN0RsVvS1sbz24CPAPdIeoT6FM1tEfFMB3ObneXFo+i8Ft3Kad5CB4iIncDOade2NX09Cvx+e6OZnZvKom4uvaTXI3QrLe8UtaRUB3zQhZWXC92S4rXoVmYudEtKffu/59CtnFzolpRaVuH5Y6c4cep03lHMLjoXuiWlmnktupWXC92Ssspr0a3EXOiWlDNr0f256FZCLnRLStUjdCsxF7olZXFvD1n/Ih9FZ6XkQrfkeC26lZUL3ZJTzSqeQ7dScqFbcmqZt/9bObnQLTm1rJ9njo5zcsKbi6xcXOiWnKmVLgcOn8w5idnF5UK35EwddDF60PPoVi4udEtO7czmIs+jW7m40C05U5/n4qWLVjYudEvOkr4elvb1eKWLlY4L3ZJUW+bPRbfycaFbkqpZv0foVjoudEtSbcDb/618XOiWpGpWYezoScYnJvOOYnbRuNAtSbWsQgQcOOJRupWHC92SdOagC0+7WIm40C1Jq5Z5LbqVjwvdkuQRupWRC92StLSvh0t6uz1Ct1JxoVuSJFHNvLnIysWFbsmqZf0eoVupuNAtWVWfXGQl01KhS9ok6XFJw5Jun+WeN0j6saTdkr7b3phm566WVThw5AQTp725yMqhZ74bJHUDdwBvAkaAByXtiIjHmu5ZBnwG2BQRT0la0aG8Zi2rZf1MBowdPUmt8ZG6ZilrZYR+DTAcEU9GxDhwL7B52j3vAO6LiKcAIuJAe2Oanbupgy48j25l0Uqhrwb2Nj0eaVxrdgXwEkn/LekhSe+e6YUkbZG0S9KusbGx80ts1iKvRbeyaaXQNcO1mPa4B/h14AbgzcDfSLrirN8UsT0ihiJiaHBw8JzDmp0Lny1qZTPvHDr1EfnapsdrgNEZ7nkmIl4AXpD0PeAq4Im2pDQ7D1n/IiqLujxCt9JoZYT+ILBB0uWSeoEbgR3T7vkq8HpJPZIWA68F9rQ3qtm5kVRfi+7Doq0k5h2hR8SEpFuB+4Fu4O6I2C1pa+P5bRGxR9I3gIeBSeCuiHi0k8HNWlHzWnQrkVamXIiIncDOade2TXv8ceDj7YtmduGqWYUfPvlc3jHMLgrvFLWk1bIKTx8+wenJ6e/jm6XHhW5Jq2b9TEwGzxw9mXcUs45zoVvSagPeXGTl4UK3pL24uchr0S19LnRLmrf/W5m40C1pl17SS2+PNxdZObjQLWn1zUUVj9CtFFzolrzqgI+is3JwoVvyPEK3snChW/KqWT9PHz7BpDcXWeJc6Ja8Wlbh1Ong2RfG845i1lEudEtezQddWEm40C15U+eJ+o1RS50L3ZJ3ZreoPxfdEudCt+Rddkkvi7rF6EEXuqXNhW7J6+oSKwcq/jwXS54L3UrBa9GtDFzoVgq1rN9z6JY8F7qVwtQIPcKbiyxdLnQrhWpWYXxikuePnco7ilnHuNCtFKY2F40e9Bujli4XupVCtbG5yLtFLWUudCuFMycX+Y1RS5gL3Uph+ZI+errkteiWNBe6lUJ3Y3OR16JbylzoVhrVrOI5dEuaC91Kw4VuqXOhW2nUBiqMHjruzUWWLBe6lUY1q3Di1CSHjntzkaXJhW6l8eJBF552sTS50K00ast8FJ2lraVCl7RJ0uOShiXdPsd9r5F0WtIfti+iWXuc2VzkQrdEzVvokrqBO4DrgI3ATZI2znLf3wH3tzukWTsMLumjS3hzkSWrlRH6NcBwRDwZEePAvcDmGe57P/AV4EAb85m1TU93FyuWVhj1CN0S1Uqhrwb2Nj0eaVw7Q9Jq4G3AtrleSNIWSbsk7RobGzvXrGYXzGvRLWWtFLpmuDZ9Ie8ngdsi4vRcLxQR2yNiKCKGBgcHW4xo1j71gy485WJp6mnhnhFgbdPjNcDotHuGgHslASwHrpc0ERH/3o6QZu1SzSp894kxIoLGz6tZMlop9AeBDZIuB34B3Ai8o/mGiLh86mtJ9wBfc5nbQrQq6+fY+GmOnJxgoLIo7zhmbTXvlEtETAC3Ul+9sgf4UkTslrRV0tZOBzRrp2rmteiWrlZG6ETETmDntGszvgEaEX9y4bHMOqP5KLorVi7NOY1Ze3mnqJWKR+iWMhe6lcqKpRUk7xa1NLnQrVR6e7pYvqTPI3RLkgvdSmdVVvFh0ZYkF7qVTn23qDcXWXpc6FY6tazfc+iWJBe6lU41q3DkxARHT07kHcWsrVzoVjq1M0sXPe1iaXGhW+lUB3zQhaXJhW6ls2qZzxa1NLnQrXRWDPQB3i1q6XGhW+n09XSzfEmvR+iWHBe6lVLVB11YglzoVkrVgX5PuVhyXOhWSvWj6FzolhYXupVSNatw6Pgpjo17c5Glw4VupbRqmT8X3dLjQrdSqg7U16K70C0lLnQrpant/55Ht5S40K2UqmcK3UsXLR0udCulyqJuXrJ4kUfolhQXupVWNfNadEuLC91Ka5XXoltiXOhWWtWswn6fLWoJcaFbadWyCs+9MM6JU6fzjmLWFi50K61q5rXolhYXupWW16JbalzoVlpTa9H3H/ZadEuDC91KyyN0S40L3UprcW8PWf8iz6FbMloqdEmbJD0uaVjS7TM8/05JDzd+fV/SVe2PatZ+/lx0S8m8hS6pG7gDuA7YCNwkaeO0234G/HZEXAl8BNje7qBmneCj6CwlrYzQrwGGI+LJiBgH7gU2N98QEd+PiOcbDx8A1rQ3plln1LKKp1wsGa0U+mpgb9Pjkca12bwX+PpMT0jaImmXpF1jY2OtpzTrkOpAP88cHefkhDcXWfG1Uuia4VrMeKP0O9QL/baZno+I7RExFBFDg4ODrac065CplS4HDp/MOYnZhWul0EeAtU2P1wCj02+SdCVwF7A5Ip5tTzyzzqot89JFS0crhf4gsEHS5ZJ6gRuBHc03SFoH3Ae8KyKeaH9Ms86o+aALS0jPfDdExISkW4H7gW7g7ojYLWlr4/ltwIeBy4DPSAKYiIihzsU2aw9/noulZN5CB4iIncDOade2NX39PuB97Y1m1nlL+npY2tfjKRdLgneKWul5LbqlwoVupVf1WnRLhAvdSm9V1u8pF0uCC91Kr5pVGDt6klOnJ/OOYnZBXOhWerWsQgQcOOLNRVZsLnQrvamDLvYd9BujVmwudCu9WmMtuufRrehc6FZ6Z46ic6FbwbnQrfQGKj0s7u32CN0Kz4VupSep/rnoPizaCs6FbkZ9Ht0jdCs6F7oZ3i1qaXChm1Ffi/704RNMeHORFZgL3Yz6CH0yYOyoNxdZcbnQzWg+6MLTLlZcLnQzXtxc5Hl0KzIXuhkeoVsaXOhmQNa/iMqiLvb7oAsrMBe6GVObi/oZ9QjdCsyFbtZQHfBadCs2F7pZQ82bi6zgXOhmDdXG5qLTk5F3FLPz4kI3a6gt62diMnjWm4usoFzoZg21AS9dtGJzoZs1nDmKzksXraBc6GYN3lxkRedCN2u49JJeeru7vNLFCsuFbtYgiWpW8QjdCsuFbtbEa9GtyFzoZk1qWYV9PlvUCsqFbtakmvXz9KGTTHpzkRVQS4UuaZOkxyUNS7p9hucl6VON5x+WdHX7o5p1Xi2rMH56kmdfGM87itk5m7fQJXUDdwDXARuBmyRtnHbbdcCGxq8twJ1tzml2UUytRfc8uhVRTwv3XAMMR8STAJLuBTYDjzXdsxn4XEQE8ICkZZJqEbGv7YnNOmhqLfrWzz/E4t7unNNYqt7+mrW87/UvbfvrtlLoq4G9TY9HgNe2cM9q4JcKXdIW6iN41q1bd65ZzTru5dUB3vHadRw85ikX65zlS/o68rqtFLpmuDb9HaNW7iEitgPbAYaGhvyuky04vT1dfPRtv5Z3DLPz0sqboiPA2qbHa4DR87jHzMw6qJVCfxDYIOlySb3AjcCOaffsAN7dWO1yLXDI8+dmZhfXvFMuETEh6VbgfqAbuDsidkva2nh+G7ATuB4YBo4BN3cuspmZzaSVOXQiYif10m6+tq3p6wBuaW80MzM7F94pamaWCBe6mVkiXOhmZolwoZuZJUL19zNz+MbSGPDz8/zty4Fn2hin04qUt0hZoVh5i5QVipW3SFnhwvL+SkQMzvREboV+ISTtioihvHO0qkh5i5QVipW3SFmhWHmLlBU6l9dTLmZmiXChm5kloqiFvj3vAOeoSHmLlBWKlbdIWaFYeYuUFTqUt5Bz6GZmdraijtDNzGwaF7qZWSIKV+jzHVi9UEhaK+k7kvZI2i3pA3lnaoWkbkn/I+lreWeZS+OYwy9L+t/Gn/Fv5J1pLpL+ovFz8KikL0qq5J2pmaS7JR2Q9GjTtUslfUvSTxv/fUmeGafMkvXjjZ+FhyX9m6RlOUb8JTPlbXrurySFpOXt+F6FKvQWD6xeKCaAv4yIVwDXArcs4KzNPgDsyTtEC/4J+EZEvBy4igWcWdJq4M+AoYh4JfWPob4x31RnuQfYNO3a7cC3I2ID8O3G44XgHs7O+i3glRFxJfAE8MGLHWoO93B2XiStBd4EPNWub1SoQqfpwOqIGAemDqxecCJiX0T8qPH1EeqFszrfVHOTtAa4Abgr7yxzkTQA/BbwLwARMR4RB3MNNb8eoF9SD7CYBXaiV0R8D3hu2uXNwGcbX38W+IOLmWk2M2WNiG9GxETj4QPUT01bEGb5swX4BPDXzHBc5/kqWqHPdhj1giZpPfBq4Ic5R5nPJ6n/gE3mnGM+LwXGgH9tTA/dJemSvEPNJiJ+Afw99ZHYPuonen0z31QtWTl18ljjvytyztOqPwW+nneIuUh6K/CLiPhJO1+3aIXe0mHUC4mkJcBXgD+PiMN555mNpLcAByLiobyztKAHuBq4MyJeDbzAwpkOOEtj7nkzcDmwCrhE0h/nmypNkj5EfbrzC3lnmY2kxcCHgA+3+7WLVuiFOoxa0iLqZf6FiLgv7zzzeB3wVkn/R30q63clfT7fSLMaAUYiYupfPF+mXvAL1e8BP4uIsYg4BdwH/GbOmVrxtKQaQOO/B3LOMydJ7wHeArwzFvYGm1+l/j/3nzT+vq0BfiSpeqEvXLRCb+XA6gVBkqjP8e6JiH/MO898IuKDEbEmItZT/3P9r4hYkKPIiNgP7JX0ssalNwKP5RhpPk8B10pa3Pi5eCML+E3cJjuA9zS+fg/w1RyzzEnSJuA24K0RcSzvPHOJiEciYkVErG/8fRsBrm78XF+QQhV6402PqQOr9wBfiojd+aaa1euAd1Ef6f648ev6vEMl5P3AFyQ9DLwK+Gi+cWbX+JfEl4EfAY9Q/3u3oLaqS/oi8APgZZJGJL0X+BjwJkk/pb4a42N5ZpwyS9ZPA0uBbzX+rm2b80UuolnyduZ7Lex/mZiZWasKNUI3M7PZudDNzBLhQjczS4QL3cwsES50M7NEuNDNzBLhQjczS8T/A0pXWu0ioV70AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_steps = 2520 # 4 minutes for 1 week = 2520, 1 hour 168, 30 minutes 336, 15 minutes 672\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "input_train, output_train = create_dataset(train,train.state,time_steps)\n",
    "input_test, output_test = create_dataset(test,test.state,time_steps)\n",
    "\n",
    "input_train_box, output_train_box = create_dataset(train_box,train_box.state,time_steps)\n",
    "input_test_box, output_test_box = create_dataset(test_box,test_box.state,time_steps)\n",
    "\n",
    "input_train_pc, output_train_pc = create_dataset(train_pc,train_pc.state,time_steps)\n",
    "input_test_pc, output_test_pc = create_dataset(test_pc,test_pc.state,time_steps)\n",
    "\n",
    "input_train_printer, output_train_printer = create_dataset(train_printer,train_printer.state,time_steps)\n",
    "input_test_printer, output_test_printer = create_dataset(test_printer,test_printer.state,time_steps)\n",
    "\n",
    "input_train_phone, output_train_phone = create_dataset(train_phone,train_phone.state,time_steps)\n",
    "input_test_phone, output_test_phone = create_dataset(test_phone,test_phone.state,time_steps)\n",
    "\n",
    "# this needs to be a float for when edges of signal are rounded\n",
    "output_train = output_train.astype(float)\n",
    "\n",
    "# concatenate the different training and test sets with eachother\n",
    "input_train_conc = np.concatenate((input_train,input_train_box,input_train_pc,input_train_printer,input_train_phone),axis=0)\n",
    "input_test_conc = np.concatenate((input_test,input_test_box,input_test_pc,input_test_printer,input_test_phone),axis=0)\n",
    "output_train_conc = np.concatenate((output_train,output_train_box,output_train_pc,output_train_printer,output_train_phone),axis=0)\n",
    "\n",
    "plt.plot(output_train_conc[25:40])\n",
    "# determines with how munch the values should minimaly be changed\n",
    "min_slope = 0.2\n",
    "# percentage of previous values to update\n",
    "pct_prev_vals = 0.5\n",
    "# counts how long ago the last edge occured\n",
    "last_change = 1\n",
    "# the first value\n",
    "previous = output_train_conc[0]\n",
    "\n",
    "for i in range(1,len(output_train_conc)):\n",
    "    # if an edge is detected\n",
    "    if(output_train_conc[i] != previous):\n",
    "        # calculate the number of previous values to update based on the percentage and maximum limit\n",
    "        num_prev_vals = min(int(pct_prev_vals * last_change), 4)\n",
    "        # calculate the slope based on the number of previous values being updated\n",
    "        slope = min(min_slope * (4 // num_prev_vals),0.3)\n",
    "        for j in range(1,num_prev_vals+1):\n",
    "            if(output_train_conc[i] == 1): # if the value changes to 1\n",
    "                # replace the value with its new value\n",
    "                # this is calculated based on the slope times how far the value is from the edge\n",
    "                output_train_conc[i - j] += slope*((num_prev_vals+1)-j) \n",
    "            else: # if the value changes to 0\n",
    "                output_train_conc[i - j] -= slope*((num_prev_vals+1)-j)\n",
    "        last_change = 1\n",
    "    else:\n",
    "        last_change += 1\n",
    "    previous = output_train_conc[i] # store the last value\n",
    "    \n",
    "# print and plot to see if rounding happens properly\n",
    "# print(output_train_conc[35:40])\n",
    "# plt.plot(output_train_conc[25:40])\n",
    "\n",
    "\n",
    "output_test_conc = np.concatenate((output_test,output_test_box,output_test_pc,output_test_printer,output_test_phone),axis=0)\n",
    "print(input_train_conc.shape, input_test_conc.shape, output_train_conc.shape, output_test_conc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36059028-1bbe-4c48-9988-8f1f1985e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(8, input_shape=(input_train_conc.shape[1],input_train_conc.shape[2]),return_sequences=True,activation='tanh')))# , input_shape=(input_train.shape[1],input_train.shape[2]), return_sequences=True)\n",
    "model.add(Dropout(0.25))\n",
    "model.add(\n",
    "    Bidirectional(LSTM(2,activation='tanh',recurrent_dropout=0))\n",
    ")\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.001), metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2fcf44-581f-4751-97c0-9485b3e0f182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 13:24:52.655217: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1942/8820 [=====>........................] - ETA: 1:01:13 - loss: 0.1494 - accuracy: 0.9549"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_train_conc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_train_conc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3037\u001b[0m   (graph_function,\n\u001b[1;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m     args,\n\u001b[1;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1968\u001b[0m     executing_eagerly)\n\u001b[1;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(input_train_conc, output_train_conc, epochs=10,batch_size=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e672f9c-68c0-479b-a14c-167494e94b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for input data\n",
    "prediction = model.predict(input_test_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01556f94-5bc8-45ae-95cc-79ef47279688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare prediction to expected output (output without rounded edges)\n",
    "plt.plot(prediction)\n",
    "plt.plot(output_test_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1429197-4be0-4ef6-a4ec-07431e5f1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom in on part of plot\n",
    "plt.plot(prediction[0:300])\n",
    "plt.plot(output_test_conc[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf4a69-303f-436b-9ddc-9117774ffa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('./saved_models/models_day_month/all_devicesV4/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a0c27-644e-453d-b001-d8cbceae6c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model in tar.gz\n",
    "!tar chvfz models_day_month.tar.gz ./saved_models/models_day_month*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6520a6-4b4c-4b43-a082-53f014362904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a backup of the entire server\n",
    "# !tar chvfz jupyter_backup.tar.gz ../../../shared/\n",
    "!tar chvfz notebook_backup.tar.gz ./prediction_state_day_month-softmax-Copy2.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
